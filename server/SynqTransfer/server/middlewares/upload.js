// middlewares/upload.js
const AWS = require("aws-sdk");
const busboy = require("busboy");
const fs = require("fs");
const multer = require("multer");
const path = require("path");
const { PassThrough } = require("stream");

AWS.config.update({
  accessKeyId: process.env.AWS_KEY,
  secretAccessKey: process.env.AWS_SECRET,
  region: process.env.AWS_REGION,
});
const s3 = new AWS.S3();
AWS.config.logger = console;

const manualStreamUpload = (req, res, next) => {
  const contentLength = parseInt(req.headers["content-length"] || "0");
  const TWO_GB = 2 * 1024 * 1024 * 1024;

  // ‚úÖ MULTER path (under 2GB)
  if (contentLength <= TWO_GB) {
    console.log("üì¶ Using Multer for upload (content-length <= 2GB)");

    const storage = multer.diskStorage({
      destination: (req, file, cb) => {
        console.log(`üìÅ Storing to /uploads/ as ${file.originalname}`);
        cb(null, "uploads/");
      },
      filename: (req, file, cb) => cb(null, Date.now() + "-" + file.originalname),
    });

    const upload = multer({ storage }).array("files");

    return upload(req, res, (err) => {
      if (err) {
        console.error("‚ùå Multer error:", err);
        return res.status(500).json({ error: "Failed to upload using Multer." });
      }
      if (!req.files || req.files.length === 0) {
        console.warn("‚ö†Ô∏è No files received via Multer");
        return res.status(400).json({ error: "No files uploaded." });
      }

      console.log(`‚úÖ Multer received ${req.files.length} files`);
      next();
    });
  }

  // ‚úÖ S3 streaming path (above 2GB)
  console.log("‚òÅÔ∏è Using S3 streaming upload via Busboy");

  const bb = busboy({ headers: req.headers });
  const files = [];
  const io = req.app.get("io");
  let uploadedSize = 0;

  bb.on("file", async (fieldname, file, fileInfo) => {
  const filename = fileInfo.filename || "unnamed";
  const key = `${Date.now()}-${filename}`;
  const partSize = 10 * 1024 * 1024; // 10MB per part
  let partNumber = 1;
  let uploadedSize = 0;
  let buffer = Buffer.alloc(0);
  const parts = [];

  const io = req.app.get("io");

  console.log(`üì§ Starting multipart upload for: ${filename}`);

  try {
    // Step 1: Initiate multipart upload
    const multipart = await s3.createMultipartUpload({
      Bucket: process.env.S3_BUCKET,
      Key: key,
      ContentType: req.headers['content-type'],
    }).promise();

    const uploadId = multipart.UploadId;
    console.log(`üÜî Multipart Upload ID: ${uploadId}`);

    // üü¢ Respond IMMEDIATELY to avoid Render timeout
    res.status(202).json({ message: "Upload started. Progress will be reported via socket." });

    // Step 2: Upload parts manually as stream
    file.on("data", async (chunk) => {
      buffer = Buffer.concat([buffer, chunk]);
      uploadedSize += chunk.length;

      if (buffer.length >= partSize) {
        file.pause();

        const partBuffer = buffer.slice(0, partSize);
        buffer = buffer.slice(partSize);

        console.log(`‚¨ÜÔ∏è Uploading part ${partNumber} (${partBuffer.length} bytes)`);

        try {
          const uploadedPart = await s3.uploadPart({
            Bucket: process.env.S3_BUCKET,
            Key: key,
            UploadId: uploadId,
            PartNumber: partNumber,
            Body: partBuffer,
          }).promise();

          parts.push({ ETag: uploadedPart.ETag, PartNumber: partNumber });

          const percent = Math.round((uploadedSize / contentLength) * 100);
          io.emit("upload-progress", { filename, percent });

          console.log(`‚úÖ Part ${partNumber} uploaded (${percent}%)`);
          partNumber++;
        } catch (err) {
          console.error(`‚ùå Failed to upload part ${partNumber}:`, err);
          io.emit("upload-error", { filename, error: `Part ${partNumber} failed` });
        }

        file.resume();
      }
    });

    file.on("end", async () => {
      try {
        if (buffer.length > 0) {
          console.log(`‚¨ÜÔ∏è Uploading final part ${partNumber} (${buffer.length} bytes)`);

          const finalPart = await s3.uploadPart({
            Bucket: process.env.S3_BUCKET,
            Key: key,
            UploadId: uploadId,
            PartNumber: partNumber,
            Body: buffer,
          }).promise();

          parts.push({ ETag: finalPart.ETag, PartNumber: partNumber });
          console.log(`‚úÖ Final part ${partNumber} uploaded`);
        }

        // Step 3: Complete upload
        await s3.completeMultipartUpload({
          Bucket: process.env.S3_BUCKET,
          Key: key,
          UploadId: uploadId,
          MultipartUpload: { Parts: parts },
        }).promise();

        io.emit("upload-complete", {
          filename,
          key,
          location: `s3://${process.env.S3_BUCKET}/${key}`,
        });

        console.log(`üéâ Multipart upload complete for: ${filename}`);
      } catch (err) {
        console.error("‚ùå Finalization failed:", err);
        io.emit("upload-error", { filename, error: "Finalization failed" });
      }
    });

  } catch (err) {
    console.error("‚ùå Error in multipart upload setup:", err);
    res.status(500).json({ error: "Multipart upload failed" });
  }
});

  bb.on("error", (err) => {
  console.error("‚ùå Busboy error:", err);
  io.emit("upload-error", { error: "Streaming upload error." });
  res.status(500).json({ error: "Streaming upload failed" });
});

  io.emit("upload-start", { message: "Upload started." });

  req.pipe(bb);
};

module.exports = manualStreamUpload;
